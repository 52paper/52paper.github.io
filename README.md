### Guideline:
- paper reading讲解的时候要深入浅出，确保自己看懂了，再用通俗的话讲出来。关键是把文章工作讲清楚，motivation，方法部分，实验是否支撑，该工作的优点和缺点，对你个人工作的启发。每部分大概2~3页slides即可。最重要的是后面两部分，需要你自己对工作批判性的阅读。
- 时间暂定是周2晚上晚饭后。 如果人不齐的话提前告知，视情况再确定时间。
- presenter务必每周5发出分享的paper，并且update到 [52paper.github.io](https://52paper.github.io/) ;在present前准备简短的slides(每篇paper<10页)及update到本页面。
- attender希望都能够提前把分享的paper至少通读一遍，积极提出问题及参与discussion。

--------------------
### 2018/9/21

|Speakers|Papers|Slides|Others|
|:----:|:----|:----:|:-----:|
|cd|NIPS2018 Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization|[[slide]](./20180921_jcykcai.pdf)|-|
||EMNLP2017 Sequential Matching Network-A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots||-|
|zhaoyang|ACL2018 Learning to Control the Specificity in Neural Response Generation|[[slide]](https://github.com/52paper/52paper.github.io/blob/master/zhaoyang_20180801.pdf)|-|
### 2018/8/1 

|Speakers|Papers|Slides|Others|
|:----:|:----|:----:|:-----:|
|gaojun|NIPS2017 [Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space](https://papers.nips.cc/paper/7158-diverse-and-accurate-image-description-using-a-variational-auto-encoder-with-an-additive-gaussian-encoding-space.pdf)|[slide]|-|
|cd|arXiv2018 [Response Generation by Context-aware Prototype Editing](https://arxiv.org/pdf/1806.07042.pdf)|[[slide]](./20180801_jcykcai.pdf)|-|
|-|arXiv2016 [Two are better than one: An ensemble of retrieval-and generation-based dialog systems](https://arxiv.org/pdf/1610.07149.pdf)|-|-|
|zhaoyang|AAAI2018 [Dictionary-Guided Editing Networks for Paraphrase Generation](https://arxiv.org/pdf/1806.08077.pdf)|[[slide]](https://github.com/52paper/52paper.github.io/blob/master/zhaoyang_20180801.pdf)|-|
|ziyang|ACL2018 [Learning to Ask Good Questions: Ranking Clarification Questions using Neural Expected Value of Perfect Information](https://arxiv.org/pdf/1805.04655.pdf)|[[slide]](./20180801_willzychen.pdf)|-|
|biwei|-|-|-|
|yahui|ACL2018 [Token-level and sequence-level loss smoothing for RNN language models](https://hal.inria.fr/hal-01790879/file/paper.pdf)|[[slide]](./20180801_amosyhliu.pdf)|-|
|-|arXiv2018 [Sounding Board: A User-Centric and Content-Driven Social Chatbot](https://arxiv.org/pdf/1804.10202.pdf)|-|-|

### 2018/7/27 ACL Report

|Speakers|Papers|Slides|Others|
|:----:|:----|:----:|:-----:|
|zhaoyang|ACL18 Report|[slide](https://github.com/52paper/52paper.github.io/blob/master/20180727_zhaoyang.pdf)|-|


### 2018/7/18 

|Speakers|Papers|Slides|Others|
|:----:|:----|:----:|:-----:|
|gaojun|ACL2017 [Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms in Sequence-to-Sequence Learning](http://www.nlpr.ia.ac.cn/cip/shizhuhe/articles/acl2017-coreqa.pdf)|[[slide]](./20180718_gaojun.pdf)|-|
|cd|ACL18 [AdvEntuRe: Adversarial Training for Textual Entailment with Knowledge-Guided Examples](http://aclweb.org/anthology/P18-1225) |[[slide]](./20180718_jcykcai.pdf)|-|
|-|ACL18 [Working Memory Networks-Augmenting Memory Networks with a Relational Reasoning Module](https://arxiv.org/pdf/1805.09354.pdf) |-|-|
|ziyang|IJCAI2018 [SentiGAN: Generating Sentimental Texts via Mixture Adversarial Networks](https://www.ijcai.org/proceedings/2018/0618.pdf)|[[slide]](./20180719_willzychen.pdf)|-|
|biwei|-|-|-|
|yahui|AAAI2015 [Self-Paced Curriculum Learning](https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/viewFile/9750/9929)|[[slide]](./20180719_amosyhliu.pdf)|-|
|-|ICML2018 [MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels](https://arxiv.org/abs/1712.05055)|-|-|

### 2018/7/3 Reinforcement Learning

|Speakers|Papers|Slides|Others|
|:----:|:----|:----:|:-----:|
|gaojun|AAAI2018 [Flexible End-to-End Dialogue System for Knowledge Grounded Conversation](https://arxiv.org/pdf/1709.04264.pdf)|[[slide]](./20180703_gaojun.pdf)|-|
|cd|Nature2017 [Mastering the game of Go Without human knowledge](https://www.nature.com/articles/nature24270.pdf)|[[slide]](./20180703_jcykcai.pdf)|-|
|ziyang|CVPR2018 [Video Captioning via Hierarchical Reinforcement Learning](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Video_Captioning_via_CVPR_2018_paper.pdf)|[[slide]](./20190703_willzychen.pdf)|-|
|biwei|ICML2017 [FeUdal Networks for Hierarchical Reinforcement Learning](https://arxiv.org/pdf/1703.01161.pdf)|[[slide]](./20180702_biwei.pdf)|-|
|yahui|IJCAI2018 [Learning to Converse with Noisy Data: Generation with Calibration](https://www.cs.jhu.edu/~npeng/papers/IJCAI18-learning-converse-noisy.pdf)|[[slide]](./20180703_amosyhliu.pdf)|-|
|-|arXiv2016 [Data Distillation for Controlling Specificity in Dialogue Generation](https://arxiv.org/pdf/1702.06703.pdf)|-|-|


### 2018/6/26 GAN review & Knowledge-incoporated Generation & RL

|Speakers|Papers|Slides|Others|
|:----:|:----|:----:|:-----:|
|xiaojiang|review [questions about GAN](./gan_report.md) again and summarize GAN's possible use in conversation resposne geneartion.|-|-|
|gaojun|IJCAI2016 [Neural Generative Question Answering](https://arxiv.org/pdf/1512.01337.pdf)|[[slide]](./20180626_gaojunv3.pdf)|-|
|-|AAAI2018 [A Knowledge-Grounded Neural Conversation Model](https://arxiv.org/pdf/1702.01932.pdf)|-|-|
|cd|ACL2018 [Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting](https://arxiv.org/pdf/1805.11080.pdf)|[[slide]](./20180625_jcykcai.pdf)|-|
|-|ACL2018 [Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach](https://arxiv.org/pdf/1805.05181.pdf)|-|-|
|yahui|NAACL2018 [Discourse-Aware Neural Rewards for Coherent Text Generation](https://arxiv.org/pdf/1805.03766.pdf)| [[slide]](./20180625_amosyhliu.pdf)|[Report of GAN](https://www.overleaf.com/read/mynrvgxpvvfh)|
|biwei|ICML2017 [Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control](https://arxiv.org/abs/1611.02796)|[[slide]](./20180625_biwei.pdf)|-|


### 2018/6/20 GAN
- xiaojiang's questions, hope we could have agreements on these three points, and output some reports:
  1. Why Seq2seq is better than the previous language model methods in generating language sequence. Why GAN is better than standard Seq2seq?
  2. GAN has been successfully appllied to many new image tasks, such as image generation. What are the best tasks of GAN for text?
  3. Why GAN has no break-through on text yet? All possible reasons.
  
|Lecturers|Papers|Slides|Others|
|:----:|:----|:----:|:-----:|
|cd|Implement Adversarial Training for Text Generation (motivations and technologies)|[[slide]](./20180621_jcykcai.pdf)|-|
|gaojun|EMNLP2017 [Neural Response Generation via GAN with an Approximate Embedding Layer∗](http://aclweb.org/anthology/D17-1065)|[[slide]](./20180620_gaojun.pdf)|-|
|-|IJCAI2018 [Commonsense Knowledge Aware Conversation Generation with Graph Attention](http://coai.cs.tsinghua.edu.cn/hml/media/files/2018_commonsense_ZhouHao_3_TYVQ7Iq.pdf)|-|-|
|yahui|EMNLP2017 [Adversarial Learning for Neural Dialogue Generation](https://nlp.stanford.edu/pubs/li2017adversarial.pdf)|[[slide]](./20180620_amosyhliu.pdf)|-|
|-|ICLR2018 [MaskGAN: Better Text Generation via Filling in the __ ](https://arxiv.org/pdf/1801.07736.pdf)|-|-|
|biwei|ICML2017 [Adversarial Feature Matching for Text Generation](https://arxiv.org/pdf/1706.03850.pdf)|[[slide]](./20180621_biwei.pdf)|-|
