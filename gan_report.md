After two long discussions, we have got some insights about GAN and reached many agreements. Let's output a tech reports to summarize.

Here is my suggested outline for this report.

1. Brief introduction to GAN, basic idea, formula of GAN.
2. GAN's characteristics, especially comparing with MLE and RL.
3. GAN for Text's main model problems and possible solutions
3.1 gradient vanish problem, how could we solve it
3.2 mode collapse, solutions
3.3 not differentiable for text, three solutions
4. GAN applied in Text, could organized by scenarios, comparing with successfully CV cases.
5. GAN's drawbaks, and why GAN for text is hard
5.1 GAN is hard to tune
5.2 Text is discrete, and hard to be represented in a continous space
5.3 others
6. Future work and in what directions we could improve GAN and use GAN in text
